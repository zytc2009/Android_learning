[Toc]

## 基本概念：

它可以把那些最终会在用户（User）和物品（Item）之间产生的连接提前找出来。以人为中心，万物互联，从已有的连接去预测未来的连接。

### 是否需要推荐系统：

1.是否建立越多连接越好

2.现有的连接数是不是很多

  公式：增加的连接数/(增加的活跃用户数*增加的有效物品数) 

### 预测问题模式

评分预测；

行为预测：

  直接预测行为本身发生的概率和预测物品的相对排序

  CTR 预估

### 常见顽疾

冷启动问题；

探索与利用问题：Exploit 和 Explore 问题

安全问题。

### 关键元素

UI 和 UE；数据；领域知识；算法。

权重大致是 4-3-2-1

### 目标思维和不确定性思维

核心词可以表述为：逻辑、因果、分层

**目标思维：**

把一个推荐系统也看做一个函数，这个函数的输入有很多：UI、UE、数据、领域知识、算法等等，输出则是我们关注的指标：留存率、新闻的阅读时间、电商的 GMV、视频的 VV 等等。

目标思维背后是“量化一切”的价值取向。最先要量化的就是目标本身，接下来要量化的是所有的优化改进动作。

**不确定思维：**

绝大多数推荐算法都是概率算法，推荐系统追求的是目标的增长，出现意外的推荐也是有益的，可以探索用户的新兴趣。

## 内容推荐

### 用户画像概念

用户向量化后的结果

**关键因素:**

维度

量化:和第三个关键元素“效果”息息

### 用户画像构建方法:

 原始数据。 通常对于用户冷启动等场景非常有用

 堆数据。方法就是堆积历史数据，做统计工作，这是最常见的用户画像数据，常见的兴趣标签。

机器学习，学习出人类无法直观理解的稠密向量。比如使用潜语义模型构建用户阅读兴趣，或者使用矩阵分解得到的隐因子，或者使用深度学习模型学习用户的 Embedding 向量。

### 构建用户画像过程：

> 文本向量化
>
> 根据行为数据把物品的结构化结果传递给用户，与用户自己的结构化信息合并

#### 文本内容向量化

关键词提取：最基础的标签来源，也为其他文本分析提供基础数据，常用 TF-IDF 和 TextRank。

实体识别：人物、位置和地点等。常用基于词典的方法结合 CRF 模型。

内容分类：将文本按照分类体系分类，用分类来表达较粗粒度的结构化信息

文本：在无人制定分类体系的前提下，无监督地将文本划分成多个类簇也很常见，别看不是标签，类簇编号也是用户画像的常见构成。

主题模型：从大量已有文本中学习主题向量，然后再预测新的文本在各个主题上的概率分布情况，也很实用，其实这也是一种聚类思想，主题向量也不是标签形式，也是用户画像的常用构成。

嵌入：“嵌入”也叫作 Embedding，从词到篇章，无不可以学习这种嵌入表达。嵌入表达是为了挖掘出字面意思之下的语义信息，并且用有限的维度表达出来。向量中各个维度上的值大小代表了词包含各个语义的多少

#### 标签选择

最常用的是两个方法：卡方检验（CHI）和信息增益（IG）。

基本思想是：

- 把物品的结构化内容看成文档；
- 把用户对物品的行为看成是类别；
- 每个用户看见过的物品就是一个文本集合；
- 在这个文本集合上使用特征选择算法选出每个用户关心的东西

##### 卡方检验:

CHI 就是卡方检验，本身是一种特征选择方法。本质上在检验“词和某个类别 C 相互独立”这个假设是否成立

前面的 TF-IDF 和 TextRank 都是无监督关键词提取算法，而卡方检验（CHI）则是**有监督**的，需要提供分类标注信息。

| 卡方检验 | 属于类别C | 不属于类别C | 总计      |
| -------- | --------- | ----------- | --------- |
| 包含词W  | A         | B           | A+B       |
| 不含词W  | C         | D           | C+D       |
| 总计     | A+C       | B+D         | N=A+B+C+D |

然后按照如下公式计算每一个词和每一个类别的卡方值：

![](images\卡方计算公式.png)

关于这个卡方值计算，这里说明几点：

1. 每个词和每个类别都要计算，只要对其中一个类别有帮助的词都应该留下；
2. 由于是比较卡方值的大小，所以公式中的 N 可以不参与计算，因为它对每个词都一样，就是总的文本数；
3. 卡方值越大，意味着偏离“词和类别相互独立”的假设越远，靠“词和类别互相不独立”这个备择假设越近。

##### 信息增益

IG 即 Information Gain，信息增益，也是一种有监督的关键词选择方法，也需要有标注信息。

**信息熵**，一批文本被标注了类别，很难猜一条文本的类别，如果其中一个类别的文本 C 数远远多于其他类别，那么这条文本就大概率属于类别 C：

- 各个类别的文本数量差不多时，信息熵就比较大。
- 其中少数类别的文本数量明显较多时，信息熵就较小。

**信息增益计算**分三步：

- 统计全局文本的信息熵；
- 统计每个词的条件熵，就是知道了一个词后再统计文本的信息熵，只不过这里要分别计算包含词和不包含词两部分的信息熵，再按照各自文本比例加权平均；
- 两者相减就是每个词的信息增益。

信息增益应用最广就是数据挖掘中的决策树分类算法，经典的决策树分类算法挑选分裂节点时就是计算各个属性的信息增益，始终挑选信息增益最大的节点作为分裂节点。

卡方检验和信息增益不同之处在于：前者是针对每一个行为单独筛选一套标签出来，后者是全局统一筛选。

这些方法都是在离线阶段批量完成的，把用户的画像生成配置成离线任务，每天更新一遍，次日就可以使用新的用户画像，当然你也可以频率更高。

### 内容推荐系统

要把基于内容的推荐做好，需要做好“**抓、洗、挖、算**”四门功课

内容推荐的框架图：

![](images\内容推荐的框架图.png)

#### 内容分析和用户分析：

基于内容的推荐，最重要的不是推荐算法，而是内容挖掘和分析。

内容分析的产出有两个：

- 结构化内容库；

- 内容分析模型。

  分类器模型；主题模型；实体识别模型；嵌入模型。

  这些模型主要用在：当新的物品刚刚进入时，需要实时地被推荐出去，这时候对内容的实时分析，提取结构化内容，再于用户画像匹配。

#### 内容推荐算法

相似性推荐和推荐匹配计算：如BM25F 算法

这两种办法虽然可以做到快速实现、快速上线，但实际上都不属于机器学习方法

机器学习算法：

一种最典型的场景：提高某种行为的转化率，如点击、收藏、转发等。那么标准的做法是：收集这类行为的日志数据，转换成训练样本，训练预估模型。

每一条样本由两部分构成：一部分是特征，包含用户端的画像内容，物品端的结构化内容，可选的还有日志记录时一些上下文场景信息，如时间、地理位置、设备等等，另一部分就是用户行为，作为标注信息，包含“有反馈”和“无反馈”两类。

用这样的样本训练一个二分类器，常用模型是逻辑回归（Logistic Regression）和梯度提升树（GBDT）或者两者的结合。在推荐匹配时，预估用户行为发生的概率，按照概率排序。这样更合理更科学，而且这一条路可以一直迭代优化下去。

### 总结：

基于内容的推荐一般是推荐系统的起步阶段，而且会持续存在，它的重要性不可取代。因为：

- 内容数据始终存在并且蕴含丰富的信息量，不好好利用就可惜了；
- 产品冷启动阶段，没有用户行为，别无选择；
- 新的物品要被推荐出去，首选内容推荐。

![](images\内容推荐.jpg)



## 近邻推荐

### 协同过滤

分为两类：

基于记忆的协同过滤（Memory-Based）；

基于模型的协同过滤（Model-Based）。

### 基于用户的协同过滤

这其实也是一个给用户聚类的过程，把用户按照兴趣口味聚类成不同的群体，给用户产生的推荐就来自这个群体的平均值。

#### 原理：

1.准备用户向量，从这个矩阵中，理论上可以给每一个用户得到一个向量。

向量有这么三个特点：

- 向量的维度就是物品的个数；
- 向量是稀疏的，也就是说并不是每个维度上都有数值；
- 向量维度上的取值可以是简单的 0 或者 1，1 表示喜欢过，0 表示没有，当然因为是稀疏向量，所以取值为 0 的就忽略了。

2.用每一个用户的向量，两两计算用户之间的相似度，设定一个相似度阈值或者设定一个最大数量，为每个用户保留与其最相似的用户。

3.为每一个用户产生推荐结果。和他“臭味相投”的用户们喜欢过的物品汇总起来，去掉用户自己已经消费过的物品，剩下的排序输出就是推荐结果

 公式：等号左边就是计算一个物品 和一个用户 u 的匹配分数，等号右边是这个分数的计算过程，分母是把和用户相似的 n 个用户的相似度加起来，分子是把这 n 个用户各自对物品的态度，按照相似度加权求和。

#### 实践

##### 1.构造矩阵

我们在做协同过滤计算时，所用的矩阵是稀疏的，简单说就是：很多矩阵元素不用存，因为是 0。这里介绍典型的稀疏矩阵存储格式。

**CSR**：这个存储稍微复杂点，是一个整体编码方式。它有三个组成：数值、列号和行偏移共同编码。

**COO**：这个存储方式很简单，每个元素用一个三元组表示（行号，列号，数值），只存储有值的元素，缺失值不存储。

把你的原始行为日志转换成上面的格式，就可以使用常用计算框架的标准输入了

##### 2.相似度计算

1）单个相似度计算问题，如果碰上向量很长，无论什么相似度计算方法，都要遍历向量，如果用循环实现就更可观了，所以通常降低相似度计算复杂度的办法有两种:

- 对向量采样计算. 可以减低维度，这个算法由 Twitter 提出，叫做 DIMSUM 算法，已经在 Spark 中实现了。
- 向量化计算，比循环快很多。也就是我们在任何地方，都要想办法把循环转换成向量来直接计算，一般像常用的向量库都天然支持的，比如 Python 的 NumPy

2）如果用户量很大，两两之间计算代价就很大。

- 将相似度计算拆成 Map Reduce 任务，将原始矩阵 Map 成 **键**为用户对，**值**为两个用户对同一个物品的评分之积，Reduce 阶段对这些乘积再求和，Map Reduce 任务结束后再对这些值归一化；
- 不用基于用户的协同过滤

另外，这种计算对象两两之间的相似度的任务，如果数据量不大，一般来说不超过百万个，然后矩阵又是稀疏的，那么有很多单机版本的工具其实更快，比如 KGraph、 GraphCHI 等。

##### 3.推荐计算

为每一个用户计算每一个物品的推荐分数，计算次数是矩阵的所有元素个数，这个代价，你当然不能接受，优化：

- 只有相似用户喜欢过的物品需要计算，这个数量相比全部物品少了很多；

- 把计算过程拆成 Map Reduce 任务。

  拆 Map Reduce 任务的做法是：

  > 1.遍历每个用户喜欢的物品列表；
  >
  > 2.获取该用户的相似用户列表；
  >
  > 3.把每一个喜欢的物品 Map 成两个记录发射出去，一个是**键**为 < 相似用户 ID，物品 ID，1> 三元组，可以拼成一个字符串，**值**为 < 相似度 >，另一个是键为 < 相似用户 ID，物品 ID，0> 三元组，值为 < 喜欢程度 * 相似度 >，其中的 1 和 0 为了区分两者，在最后一步中会用到；
  >
  > 4.Reduce 阶段，求和后输出；
  >
  > 5.< 相似用户 ID，物品 ID, 0> 的值除以 < 相似用户 ID，物品 ID, 1> 的值

##### 4 一些改进

改进主要集中在用户对物品的喜欢程度上：

- 惩罚对热门物品的喜欢程度，这是因为，热门的东西很难反应出用户的真实兴趣，更可能是被煽动，或者无聊随便点击的情形，这是群体行为常见特点；
- 增加喜欢程度的时间衰减，一般使用一个指数函数，指数就是一个负数，值和喜欢行为发生时间间隔正相关即可

##### 应用场景

基于用户的协同过滤有两个产出：

- 相似用户列表； 推荐用户
- 基于用户的推荐结果； 推荐内容

### 基于物品（Item-Based）协同过滤

#### 原理

基于用户的协同过滤的问题：

- 用户数量往往比较大，计算起来非常吃力，成为瓶颈；

- 用户变化很快，不是静态的，所以兴趣迁移问题很难反应出来；

- 数据稀疏，用户和用户之间有共同的消费行为实际上是比较少的，而且一般都是一些热门物品，对发现用户兴趣帮助也不大。

  

基于物品的协同过滤首先计算相似物品，然后再根据用户消费过、或者正在消费的物品为其推荐相似的：

- 物品的数量，或者严格的说，可以推荐的物品数量往往少于用户数量；所以一般计算物品之间的相似度就不会成为瓶颈。

- 物品之间的相似度比较静态，它们变化的速度没有用户的口味变化快；所以完全解耦了用户兴趣迁移这个问题。

- 物品对应的消费者数量较大，对于计算物品之间的相似度稀疏度是好过计算用户之间相似度的。

  

基本步骤：

- 构建用户物品的关系矩阵，矩阵元素可以是用户的消费行为，也可以是消费后的评价，还可以是对消费行为的某种量化如时间、次数、费用等；
- 假如矩阵的行表示物品，列表示用户的话，那么就两两计算行向量之间的相似度，得到物品相似度矩阵，行和列都是物品；
- 产生推荐结果，根据推荐场景不同，有两种产生结果的形式。一种是为某一个物品推荐相关物品，另一种是在个人首页产生类似“猜你喜欢”的推荐结果。

#### 计算物品相似度

从用户物品关系矩阵中得到的物品向量特点：

- 它是一个稀疏向量；
- 向量的维度是用户，一个用户代表向量的一维，这个向量的总共维度是总用户数量；
- 向量各个维度的取值是用户对这个物品的消费结果，可以是行为本身的布尔值，也可以是消费行为量化如时间长短、次数多少、费用大小等，还可以是消费的评价分数；
- 没有消费过的就不再表示出来，所以说是一个稀疏向量。

如何两两计算物品的相似度，一般选择余弦相似度，公式：

> 分母是计算两个物品向量的长度，求元素值的平方和再开方。分子是两个向量的点积，相同位置的元素值相乘再求和。

物品之间的相似度计算是这个算法最可以改进的地方。通常的改进方向有下面两种。

1. 物品中心化。把矩阵中的分数，减去的是物品分数的均值；先计算每一个物品收到评分的均值，然后再把物品向量中的分数减去对应物品的均值。  这样做的目的是什么呢？抑制铁杆粉丝群体的非理性因素。
2.  用户中心化。把矩阵中的分数，减去对应用户分数的均值；先计算每一个用户的评分均值，然后把他打过的所有分数都减去这个均值。这样仅仅保留了偏好，去掉了主观成分。毕竟每个人的标准不同

这种相似度计算方法，不只是适用于评分类矩阵，也适用于行为矩阵。所谓行为矩阵，即矩阵元素为 0 或者 1 的布尔值，也就是在前面的专栏中讲过的隐式反馈。隐式反馈取值特殊，有一些基于物品的改进推荐算法无法应用，比如著名的 Slope One 算法。

#### 计算推荐结果

有两种应用场景

##### 第一种属于 TopK 推荐，形式上也常常属于类似“猜你喜欢”这样的。

汇总和“用户已经消费过的物品相似”的物品，按照汇总后分数从高到低推出。核心思想就和基于用户的推荐算法一样，用相似度加权汇总。

和基于物品的推荐一样，我们在计算时不必对所有物品都计算一边，只需要按照用户评分过的物品，逐一取出和它们相似的物品出来就可以了。

这个过程都是离线完成后，去掉那些用户已经消费过的，保留分数最高的 k 个结果存储

##### 第二种属于相关推荐

这类推荐不需要提前合并计算，当用户访问一个物品的详情页面时，或者完成一个物品消费的结果面，直接获取这个物品的相似物品推荐



#### Slope One 算法

经典的基于物品推荐，相似度矩阵计算无法实时更新，整个过程都是离线计算的，而且还有另一个问题，相似度计算时没有考虑相似度的置信问题。例如，两个物品，他们都被同一个用户喜欢了，且只被这一个用户喜欢了，那么余弦相似度计算的结果是 1，这个 1 在最后汇总计算推荐分数时，对结果的影响却最大。

Slope One 算法专门针对评分矩阵，不适用于行为矩阵。Slope One 算法计算的不是物品之间的相似度，而是计算的物品之间的距离，相似度的反面。

| 用户  | 物A    | 物B  | 物C    |
| ----- | ------ | ---- | ------ |
| 用户1 | 5      | 3    | 2      |
| 用户2 | 3      | 4    | 没评分 |
| 用户3 | 没评分 | 2    | 5      |

两两计算物品之间的差距（差距/共同用户数）

|      | 物A                   | 物B       | 物C     |
| ---- | --------------------- | --------- | ------- |
| 物A  | 0                     | -0.5（2） | -3（1） |
| 物B  | 0.5（2）= (5+3-3-4)/2 | 0         | -1（2） |
| 物C  | 3（1）                | 1（2）    | 0       |

括号里表示两个物品的共同用户数量，代表两个物品差距的置信程度。比如物品 A 和物品 B 之间的差距是 0.5，共同用户数是 2，反之，物品 B 和物品 A 的差距是 -0.5，共同用户数还是 2。

用户 3 给物品 B 的评分是 2，那么预测用户 3 给物品 A 的评分呢就是 2.5，因为从物品 B 到物品 A 的差距是 0.5。同理根据物品C对物A评分就是8分。

汇总分数:把单个预测的分数按照共同用户数加权求平均。

（8∗1+2.5∗2）/(1+2) = 4.33

#### 相似度的本质

推荐算法中的相似度门派，实际上有这么一个**潜在假设**：**如果两个物体很相似，也就是距离很近，那么这两个物体就很容易产生一样的动作。**

机器学习中，也有很多算法在某种角度看做是相似度度量。例如，逻辑回归或者线性回归中，一边是特征向量，另一边是模型参数向量，两者的点积运算，就可以看做是相似度计算，只不过其中的模型参数向量值并不是人肉指定的，而是从数据中由优化算法自动总结出来的。

在近邻推荐中，最常用的相似度是余弦相似度。然而可以选用的相似度并不只是余弦相似度，还有欧氏距离、皮尔逊相关度、自适应的余弦相似度、局部敏感哈希等

#### 相似度的计算方法

##### 数据分类:

向量的数值就有两种: 实数值； 布尔值，也就是 0 或者 1。

##### 1 欧氏距离

欧氏距离，如名字所料，是一个欧式空间下度量距离的方法。通常相似度计算度量结果希望是[-1，1]或者[0，1]之间, 所以一般要做转化，距离加一后取倒数。这个公式能够把范围为 0 到正无穷的欧式距离转换为 0 到 1 的相似度。

欧式距离度量的是空间中两个点的绝对差异，适用于分析用户能力模型之间的差异，比如消费能力、贡献内容的能力等。

##### 2 余弦相似度

余弦相似度在度量文本相似度、用户相似度、物品相似度的时候都较为常用；但是在这里需要提醒你一点，余弦相似度的特点：它与向量的长度无关。因为余弦相似度计算需要对向量长度做归一化。

这意味着：两个向量，只要方向一致，无论程度强弱，都可以视为“相似”。

针对这个问题，对余弦相似度有个改进，改进的算法叫做调整的余弦相似度（Adjusted Cosine Similarity）。调整的方法很简单，就是先计算向量每个维度上的均值，然后每个向量在各个维度上都减去均值后，再计算余弦相似度。

##### 3 皮尔逊相关度

皮尔逊相关度，实际上也是一种余弦相似度，不过先对向量做了中心化，向量 p 和 q 各自减去向量的均值后，再计算余弦相似度。

皮尔逊相关度计算结果范围在 -1 到 1。-1 表示负相关，1 比表示正相关。皮尔逊相关度其实度量的是两个随机变量是不是在**同增同减**。

由于皮尔逊相关度度量的时两个变量的变化趋势是否一致，所以不适合用作计算布尔值向量之间相关度，因为两个布尔向量也就是对应两个 0-1 分布的随机变量，这样的随机变量变化只有有限的两个取值

##### 4 杰卡德（Jaccard）相似度

杰卡德相似度，是两个集合的交集元素个数在并集中所占的比例。由于集合非常适用于布尔向量表示，所以杰卡德相似度简直就是为布尔值向量私人定做的。

对应的计算方式是：

- 分子是两个布尔向量做点积计算，得到的就是交集元素个数；
- 分母是两个布尔向量做或运算，再求元素和。

余弦相似度适用于评分数据，杰卡德相似度适合用于隐式反馈数据。例如，使用用户的收藏行为，计算用户之间的相似度。

#### 总结：

按照向量维度取值是否是布尔值来看，杰卡德相似度就只适合布尔值向量，余弦相似度弹性略大，适合两种向量。欧式距离度量的是绝对差异，余弦相似度度量的是方向差异，但是调整的余弦相似度则可以避免这个弱点。

![](images\近邻推荐.jpg)

## 矩阵分解

### 为什么要矩阵分解

近邻模型无法解决的问题：

1. 物品之间存在相关性，信息量并不随着向量维度增加而线性增加；
2. 矩阵元素稀疏，计算结果不稳定，增减一个向量维度，导致近邻结果差异很大的情况存在。

矩阵分解，直观上说来简单，就是把原来的大矩阵，近似分解成两个小矩阵的乘积，在实际推荐计算时不再使用大矩阵，而是使用分解得到的两个小矩阵。

#### 1 基础的 SVD 算法

SVD 全称奇异值分解，属于线性代数的知识 ;推荐算法中实际上使用的是一个伪奇异值分解。

把用户和物品都映射到一个 k 维空间中，每一个维度也没有名字，所以常常叫做隐因子。每一个物品都得到一个向量 q，每一个用户也得到一个向量 p。q和p 中的元素，有正有负。

看上去很简单，难在哪呢？难在如何得到每一个用户，每一个物品的 k 维向量。这是一个机器学习问题。按照机器学习框架，一般就是考虑两个核心要素：

- 损失函数；
- 优化算法。

SVD 的损失函数，如果你不是算法工程师的话不必深究这个过程。

> 损失函数由两部分构成，加号前一部分控制着模型的偏差，加号后一部分控制着模型的方差。就是一个负责衡量模型准不准，另一个负责衡量模型稳不稳定。

整个 SVD 的学习过程就是：

1. 准备好用户物品的评分矩阵，每一条评分数据看做一条训练样本；
2. 给分解后的 U 矩阵和 V 矩阵随机初始化元素值；
3. 用 U 和 V 计算预测后的分数；
4. 计算预测的分数和实际的分数误差；
5. 按照梯度下降的方向更新 U 和 V 中的元素值；
6. 重复步骤 3 到 5，直到达到停止条件。

得到分解后的矩阵之后，实质上就是得到了每个用户和每个物品的隐因子向量，拿着物品和用户两个向量，计算点积就是推荐分数了。

#### 2 增加偏置信息

为了防止铁粉和用户的标准不一造成的干扰，一个用户给一个物品的评分会由四部分相加：r=μ+bi+bu+pq

等号右边从左至右分别代表：全局平均分、物品的评分偏置、用户评分的偏置、用户和物品之间的兴趣偏好。

举例：你是一个对电影非常严格的人，你一般打分比平均分都要低 0.5，所以前三项从左到右分别就是 3，1，-0.5。如果简单的就靠这三项，也可以给计算出一个你会给《肖申克的救赎》打的分数，就是 3.5。

#### 3 增加历史行为

SVD 中结合用户的隐式反馈行为和属性，这套模型叫做 SVD++。

先说隐式反馈怎么加入，方法是：除了假设评分矩阵中的物品有一个隐因子向量外，用户有过行为的物品集合也都有一个隐因子向量，维度是一样的。把用户操作过的物品隐因子向量加起来，用来表达用户的兴趣偏好。

类似的，用户属性，全都转换成 0-1 型的特征后，对每一个特征也假设都存在一个同样维度的隐因子向量，一个用户的所有属性对应的隐因子向量相加，也代表了他的一些偏好。

综合两者，SVD++ 的目标函数中，只需要把推荐分数预测部分稍作修改，原来的用户向量那部分增加了隐式反馈物品向量和用户属性向量

这样一来，在用户没有评分时，也可以用他的隐式反馈和属性做出一定的预测。

#### 4 考虑时间因素

在 SVD 中考虑时间因素，有几种做法：

1. 对评分按照时间加权，让久远的评分更趋近平均值；
2. 对评分时间划分区间，不同的时间区间内分别学习出隐因子向量，使用时按照区间使用对应的隐因子向量来计算；
3. 对特殊的期间，如节日、周末等训练对应的隐因子向量。

### 交替最小二乘原理 (ALS)

这是Facebook 在他们的推荐系统中选择的主要矩阵分解方法

交替最小二乘的核心是交替，什么意思呢？你的任务是找到两个矩阵 P 和 Q，让它们相乘后约等于原矩阵 R

通过迭代的方式解决了这个难题：

1. 初始化随机矩阵 Q 里面的元素值；
2. 把 Q 矩阵当做已知的，直接用线性代数的方法求得矩阵 P；
3. 得到了矩阵 P 后，把 P 当做已知的，故技重施，回去求解矩阵 Q；
4. 上面两个过程交替进行，一直到误差可以接受为止。

交替最小二乘有这么几个好处：

1. 在交替的其中一步，也就是假设已知其中一个矩阵求解另一个时，要优化的参数是很容易并行化的；
2. 在不那么稀疏的数据集合上，交替最小二乘通常比随机梯度下降要更快地得到结果，这一点就是隐式反馈的内容。

### 隐式反馈

矩阵分解算法，是为解决评分预测问题而生的。实际上推荐系统关注的是预测行为，行为也就是一再强调的隐式反馈。

那如何从解决评分预测问题转向解决预测行为上来呢？这就是另一类问题了，行话叫做 One-Class。收集到的数据只有明确的一类：用户干了某件事，而用户明确“不干”某件事的数据却没有明确表达。所以这就是 One-Class 的由来，One-Class 数据也是隐式反馈的通常特点。

对隐式反馈的矩阵分解，需要将交替最小二乘做一些改进，改进后的算法叫做加权交替最小二乘：Weighted-ALS。

加权交替最小二乘这样对待隐式反馈：

- 如果用户对物品无隐式反馈则认为评分是 0；
- 如果用户对物品有至少一次隐式反馈则认为评分是 1，次数作为该评分的置信度。

置信度 Cui 这样计算：cui=1+αC， 其中阿尔法是一个超参数，需要调教，默认值取 40 可以得到差不多的效果，C 就是次数了。

那些没有反馈的缺失值，就是在我们的设定下，取值为 0 的评分就非常多，有两个原因导致在实际使用时要注意这个问题：

1. 本身隐式反馈就只有正类别是确定的，负类别是我们假设的，你要知道，One-Class 并不是随便起的名字；
2. 这会导致正负类别样本非常不平衡，严重倾斜到 0 评分这边。

方法：

   按照物品的热门程度采样。

什么样的样本最适合做负样本？按照物品热门程度采样的思想就是：一个越热门的物品，用户越可能知道它的存在。那这种情况下，用户还没对它有反馈就表明：这很可能就是真正的负样本。

### 推荐计算

在得到了分解后的矩阵后，相当于每个用户得到了隐因子向量，这是一个稠密向量，同时每个物品也得到了一个稠密向量。如果计算推荐结果，实际上复杂度还是很高，尤其对于用户数量和物品数量都巨大的应用。

Facebook 提出了两个办法得到真正的推荐结果：

**第一种**，利用一些专门设计的数据结构存储所有物品的隐因子向量，从而实现通过一个用户向量可以返回最相似的 K 个物品。

Facebook 给出了自己的开源实现 Faiss，类似的开源实现还有 Annoy，KGraph，NMSLIB。其中 Facebook 开源的 Faiss 和 NMSLIB（Non-Metric Space Library）都用到了 ball tree 来存储物品向量。

如果需要动态增加新的物品向量到索引中，推荐使用 Faiss，如果不是，推荐使用 NMSLIB 或者 KGraph。

**第二种**，就是拿着物品的隐因子向量先做聚类，海量的物品会减少为少量的聚类。然后再逐一计算用户和每个聚类中心的推荐分数，给用户推荐物品就变成了给用户推荐物品聚类。

得到给用户推荐的聚类后，再从每个聚类中挑选少许几个物品作为最终推荐结果。这样做的好处除了大大减小推荐计算量之外，还可以控制推荐结果的多样性，因为可以控制在每个类别中选择的物品数量。

### 矩阵分解的不足

得到矩阵分解结果后，常常在实际使用时，是用这个预测结果来排序

这种针对单个用户对单个物品的偏好程度进行预测，得到结果后再排序的问题，在排序学习中的行话叫做 point-wise，其中 point 意思就是：只单独考虑每个物品

与之相对的，还有直接预测物品两两之间相对顺序的问题，就叫做 pair-wise，pair，顾名思义就是成对成双。

矩阵分解都属于 point-wise 模型。这类模型的尴尬是：只能收集到正样本，没有负样本，于是认为缺失值就是负样本，再以预测误差为评判标准去使劲逼近这些样本

### 贝叶斯个性化排序

均方根误差用于评价模型预测精准程度的。要关注相对排序，用什么指标比较好呢？答案是 AUC，AUC 全称是 Area Under Curve，意思是曲线下的面积，这里的曲线就是 ROC 曲线。

#### AUC

AUC 这个值在数学上等价于：模型把关心的那一类样本排在其他样本前面的概率。最大是 1，完美结果，而 0.5 就是随机排列，0 就是完美地全部排错。

AUC 怎么计算呢？一般步骤如下。

1. 用模型给样本计算推荐分数，比如样本都是用户和物品这样一对一对的，同时还包含了有无反馈的标识；
2. 得到打过分的样本，每条样本保留两个信息，第一个是分数，第二个是 0 或者 1，1 表示用户消费过，是正样本，0 表示没有，是负样本；
3. 按照分数对样本重新排序，降序排列；给每一个样本赋一个排序值，第一位 r1 = n，第二位 r2 = n-1，以此类推；
4. 其中要注意，如果几个样本分数一样，需要将其排序值调整为他们的平均值；
5. 最终按照下面这个公式计算就可以得到 AUC 值。

**BPR 模型：**

它提出了一个优化准则和学习框架。

那到底 BPR 做了什么事情呢？主要有三点：

- 一个样本构造方法；
- 一个模型目标函数；
- 一个模型学习框架。

#### 构造样本

矩阵分解训练时候处理的样本是：用户、物品、反馈，这样的三元组形式。

BPR 则不同，提出要关心的是物品之间对于用户的相对顺序，于是构造的样本是：用户、物品 1、物品 2、两个物品相对顺序，这样的四元组形式，其中，“两个物品的相对顺序”，取值是：

- 如果物品 1 是消费过的，而物品 2 不是，那么相对顺序取值为 1，是正样本；
- 如果物品 1 和物品 2 刚好相反，则是负样本；
- 样本中不包含其他情况：物品 1 和物品 2 都是消费过的，或者都是没消费过的。

学习的数据是反应用户偏好的相对顺序，而在使用时，面对的是所有用户还没消费过的物品，这些物品仍然可以在这样的模型下得到相对顺序

#### 目标函数

先假装矩阵分解结果已经有了，于是就计算出用户对于每个物品的推荐分数，只不过这个推荐分数可能并不满足均方根误差最小，而是满足物品相对排序最佳。

得到了用户和物品的推荐分数后，就可以计算四元组的样本中，物品 1 和物品 2 的分数差，这个分数可能是正数，也可能是负数，也可能是 0

用个符号来表示这个差：Xu12，表示的是对用户 u，物品 1 和物品 2 的矩阵分解预测分数差。然后再用 sigmoid 函数把这个分数差压缩到 0 到 1 之间。

也其实就是用这种方式预测了物品 1 排在物品 2 前面的似然概率，所以最大化交叉熵就是目标函数了。

目标函数通常还要防止过拟合，加上正则项，正则项其实认为模型参数还有个先验概率，这是贝叶斯学派的观点

BPR 认为模型的先验概率符合正态分布，对应到正则化方法就是 L2 正则

把这个目标函数化简和变形后，和把 AUC 当成目标函数是非常相似的，也正因为如此，BPR 模型的作者敢于宣称该模型是为 AUC 而生的。

#### 训练方法

梯度下降可以承担这件事，梯度下降又有批量梯度和随机梯度下降两个选择，前者收敛慢，后者训练快却不稳定。因此 BPR 的作者使用了一个介于两者之间的训练方法，结合重复抽样的梯度下降。具体来说是这样做的：

1. 从全量样本中有放回地随机抽取一部分样本；
2. 用这部分样本，采用随机梯度下降优化目标函数，更新模型参数；
3. 重复步骤 1，直到满足停止条件。

### 总结

传统的矩阵分解，无论是隐式反馈还是显式反馈，都是希望更加精准地预测用户对单个物品的偏好，而实际上，如果能够预测用户对物品之间的相对偏好，则更加符合实际需求的直觉。

BPR 就是这样一整套针对排序的推荐算法，它事实上提出了一个优化准则和一个学习框架，至于其中优化的对象是不是矩阵分解并不是它的重点。







## 组建团队及学习路径

### 团队组建

算法工程师，软件开发工程师，其他非技术角色

### 个人成长

- 有较强的工程能力，能快速交付高效率少 Bug 的算法实现，虽然项目中不一定要写非常大量的代码；
- 有较强的理论基础，能看懂最新的论文，虽然不一定要原创出漂亮的数学模型；
- 有很好的可视化思维，能将不直观的数据规律直观地呈现出来，向非工程师解释清楚问题所在，原理所在。

除此之外，还有一些非典型工程师的加分项：

学习能力，沟通能力，表达能力